## Elastic Cloud on Kubernetes

### éƒ¨ç½² ECK

1. å®‰è£… CRD

   ```sh
   $ kubectl create -f https://download.elastic.co/downloads/eck/2.4.0/crds.yaml
   customresourcedefinition.apiextensions.k8s.io/agents.agent.k8s.elastic.co created
   customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created
   customresourcedefinition.apiextensions.k8s.io/beats.beat.k8s.elastic.co created
   customresourcedefinition.apiextensions.k8s.io/elasticmapsservers.maps.k8s.elastic.co created
   customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created
   customresourcedefinition.apiextensions.k8s.io/enterprisesearches.enterprisesearch.k8s.elastic.co created
   customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created
   ```

2. å®‰è£…å¸¦æœ‰ RBAC rules çš„ operatorï¼š

   ```sh
   $ kubectl apply -f https://download.elastic.co/downloads/eck/2.4.0/operator.yaml
   namespace/elastic-system created
   serviceaccount/elastic-operator created
   secret/elastic-webhook-server-cert created
   configmap/elastic-operator created
   clusterrole.rbac.authorization.k8s.io/elastic-operator created
   clusterrole.rbac.authorization.k8s.io/elastic-operator-view created
   clusterrole.rbac.authorization.k8s.io/elastic-operator-edit created
   clusterrolebinding.rbac.authorization.k8s.io/elastic-operator created
   service/elastic-webhook-server created
   statefulset.apps/elastic-operator created
   validatingwebhookconfiguration.admissionregistration.k8s.io/elastic-webhook.k8s.elastic.co created
   ```

   > ECK operator é»˜è®¤åœ¨ elastic-system å‘½åç©ºé—´ä¸­è¿è¡Œã€‚å»ºè®®æ‚¨ä¸ºå·¥ä½œè´Ÿè½½é€‰æ‹©ä¸“ç”¨å‘½åç©ºé—´ï¼Œè€Œä¸æ˜¯ä½¿ç”¨`elastic-system` æˆ– `default` å‘½åç©ºé—´ã€‚

3. æŸ¥çœ‹ operator æ—¥å¿—ï¼š

   ```sh
   $ kubectl -n elastic-system logs -f statefulset.apps/elastic-operator
   ```

### éƒ¨ç½² Elasticsearch é›†ç¾¤

#### è‡ªå®šä¹‰ `elastic` ç”¨æˆ·å¯†ç 

Operator é»˜è®¤ä¼šåˆ›å»ºåŒ…å«é»˜è®¤ç”¨æˆ· `elastic` å¯†ç çš„ secretï¼ˆ`elastk8s-es-elastic-user`ï¼‰ï¼Œæˆ‘ä»¬é€šè¿‡åˆ›å»ºåŸºæœ¬èº«ä»½éªŒè¯çš„ secret ä¸º `elastic` ç”¨æˆ·æŒ‡å®šå¯†ç ï¼Œåˆ™ operator ä¸å†åˆ›å»ºåŒ…å« `elastic` å¯†ç çš„ secretã€‚

```sh
$ $ cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: secret-basic-auth
  namespace: elastic-system
type: kubernetes.io/basic-auth
stringData:
  username: elastic
  password: elastic.admin
  roles: superuser
EOF
```

æŸ¥çœ‹ secret è¯¦ç»†ä¿¡æ¯ï¼š

```sh
$ kubectl get secret -n elastic-system secret-basic-auth -o yaml
apiVersion: v1
data:
  password: ZWxhc3RpYy5hZG1pbg==
  roles: c3VwZXJ1c2Vy
  username: ZWxhc3RpYw==
kind: Secret
...
```

#### åˆ›å»º Elasticsearch é›†ç¾¤

æ­¤ç¤ºä¾‹è®¾ç½®ä¸€ä¸ªå…·æœ‰ 4 ä¸ªèŠ‚ç‚¹çš„ Elasticsearch é›†ç¾¤ï¼Œå…¶ä¸­ 1 ä¸ª master èŠ‚ç‚¹ï¼Œ3 ä¸ª data èŠ‚ç‚¹ã€‚

```sh
$ cat <<EOF | kubectl apply -f -
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: elastk8s-cluster
  namespace: elastic-system
  annotations:
    eck.k8s.elastic.co/downward-node-labels: "topology.kubernetes.io/zone"
namespace: elastic-system
spec:
  version: 8.4.1
  auth:
    fileRealm:
    - secretName: secret-basic-auth
  # DeleteOnScaledownAndClusterDeletion(default): all pvc are deleted together with the es cluster
  # DeleteOnScaledownOnly: keeps the pvc when deleting the es cluster
  volumeClaimDeletePolicy: DeleteOnScaledownOnly
  updateStrategy:
    changeBudget:
      maxSurge: -1
      maxUnavailable: 1
  podDisruptionBudget:
    spec:
      minAvailable: 2
      selector:
        matchLabels:
          elasticsearch.k8s.elastic.co/cluster-name: elastk8s-cluster
  nodeSets:
  # 1 dedicated master node
  - name: master-node
    count: 1
    config:
      node.roles: ["master"]
      xpack.ml.enabled: false
      node.store.allow_mmap: false
      cluster.routing.allocation.awareness.attributes: k8s_node_name,zone
      node.attr.zone: ${ZONE}
    podTemplate:
      spec:
        #initContainers:
        #- name: sysctl
        #  securityContext:
        #    privileged: true
        #    runAsUser: 0
        #  command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
        containers:
        - name: elasticsearch
          resources:
            limits:
              memory: 8Gi
              cpu: 2
          env:
          - name: ZONE
            valueFrom:
              fieldRef:
                fieldPath: metadata.annotations['topology.kubernetes.io/zone']
          - name: ES_JAVA_OPTS
            value: "-Xms2g -Xmx2g"
        affinity:
          podAntiAffinity:
            #requiredDuringSchedulingIgnoredDuringExecution:
            preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    elasticsearch.k8s.elastic.co/cluster-name: elastk8s-cluster
                topologyKey: kubernetes.io/hostname
        topologySpreadConstraints:
          - maxSkew: 1
            topologyKey: topology.kubernetes.io/zone
            whenUnsatisfiable: DoNotSchedule
            labelSelector:
              matchLabels:
                elasticsearch.k8s.elastic.co/cluster-name: elastk8s-cluster
                elasticsearch.k8s.elastic.co/statefulset-name: elastk8s-cluster-es-default
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data # Do not change this name unless you set up a volume mount for the data path.
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 50Gi
        storageClassName: aisino-sc
  # 3 ingest-data nodes
  - name: data-nodes
    count: 3
    config:
      node.roles: ["data", "ingest"]
      xpack.ml.enabled: false
      node.store.allow_mmap: false
      cluster.routing.allocation.awareness.attributes: k8s_node_name,zone
      node.attr.zone: ${ZONE}
    podTemplate:
      spec:
        #initContainers:
        #- name: sysctl
        #  securityContext:
        #    privileged: true
        #    runAsUser: 0
        #  command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
        containers:
        - name: elasticsearch
          resources:
            limits:
              memory: 8Gi
              cpu: 2
          env:
          - name: ZONE
            valueFrom:
              fieldRef:
                fieldPath: metadata.annotations['topology.kubernetes.io/zone']
          - name: ES_JAVA_OPTS
            value: "-Xms2g -Xmx2g"
        affinity:
          podAntiAffinity:
            #requiredDuringSchedulingIgnoredDuringExecution:
            preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    elasticsearch.k8s.elastic.co/cluster-name: elastk8s-cluster
                topologyKey: kubernetes.io/hostname
          #nodeAffinity:
          #  requiredDuringSchedulingIgnoredDuringExecution:
          #    nodeSelectorTerms:
          #    - matchExpressions:
          #      - key: environment
          #        operator: In
          #        values:
          #        - e2e
          #        - production
          #  preferredDuringSchedulingIgnoredDuringExecution:
          #    - weight: 1
          #      preference:
          #        matchExpressions:
          #        - key: diskType
          #          operator: In
          #          values:
          #          - ssd
        # 
        topologySpreadConstraints:
          - maxSkew: 1
            topologyKey: topology.kubernetes.io/zone
            whenUnsatisfiable: DoNotSchedule
            labelSelector:
              matchLabels:
                elasticsearch.k8s.elastic.co/cluster-name: elastk8s-cluster
                elasticsearch.k8s.elastic.co/statefulset-name: elastk8s-cluster-es-default
        #nodeSelector:
        #  diskType: ssd
        #  environment: production
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data # Do not change this name unless you set up a volume mount for the data path.
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 500Gi
        storageClassName: aisino-sc
EOF
```

Operator è‡ªåŠ¨åˆ›å»ºå’Œç®¡ç† Kubernetes èµ„æºï¼Œä»¥å®ç° Elasticsearch é›†ç¾¤æ‰€éœ€çš„çŠ¶æ€ã€‚åˆ›å»ºæ‰€æœ‰èµ„æºå¹¶å‡†å¤‡å¥½ä½¿ç”¨é›†ç¾¤å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ã€‚

> è®¾ç½® node.store.allow_mmap: false ä¼šå½±å“æ€§èƒ½ï¼Œåº”è¯¥é’ˆå¯¹ç”Ÿäº§å·¥ä½œè´Ÿè½½è¿›è¡Œè°ƒæ•´ã€‚

#### ç›‘æ§é›†ç¾¤å¥åº·å’Œåˆ›å»ºè¿›åº¦

è·å– Kubernetes é›†ç¾¤ä¸­å½“å‰ Elasticsearch é›†ç¾¤çš„æ¦‚è§ˆï¼ŒåŒ…æ‹¬è¿è¡ŒçŠ¶å†µã€ç‰ˆæœ¬å’ŒèŠ‚ç‚¹æ•°ï¼š

```sh
$ kubectl get elasticsearch -n elastic-system 
NAME               HEALTH   NODES   VERSION   PHASE   AGE
elastk8s-cluster   green    4       8.4.1     Ready   66m
```

åˆ›å»ºé›†ç¾¤æ—¶ï¼Œæ²¡æœ‰ HEALTH çŠ¶æ€ï¼ŒPHASE ä¸ºç©ºã€‚ä¸€æ®µæ—¶é—´åï¼ŒPHASE å˜ä¸º Readyï¼ŒHEALTH å˜ä¸ºç»¿è‰²ã€‚ HEALTH çŠ¶æ€æ¥è‡ª [Elasticsearchâ€™s cluster health API](https://www.elastic.co/guide/en/elasticsearch/reference/8.4/cluster-health.html).

æŸ¥çœ‹ Pod è¿è¡ŒçŠ¶æ€ï¼š

```sh
$ kubectl get pods -n elastic-system --selector='elasticsearch.k8s.elastic.co/cluster-name=elastk8s-cluster'
NAME                                READY   STATUS    RESTARTS   AGE
elastk8s-cluster-es-data-nodes-0    1/1     Running   0          68m
elastk8s-cluster-es-data-nodes-1    1/1     Running   0          68m
elastk8s-cluster-es-data-nodes-2    1/1     Running   0          68m
elastk8s-cluster-es-master-node-0   1/1     Running   0          68m
```

#### è¯·æ±‚ Elasticsearch è®¿é—®æƒé™

ClusterIP æœåŠ¡ä¼šè‡ªåŠ¨ä¸ºæ‚¨çš„é›†ç¾¤åˆ›å»ºï¼š

```sh
$ kubectl get service elastk8s-cluster-es-http -n elastic-system
NAME                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
elastk8s-cluster-es-http   ClusterIP   10.96.237.158   <none>        9200/TCP   71m
```

è¯·æ±‚ Elasticsearch ç«¯ç‚¹

```sh
$ kubectl port-forward -n elastic-system service/elastk8s-cluster-es-http 9200
```

ç„¶åè¯·æ±‚æœ¬åœ°ä¸»æœºï¼š

```sh
$ curl -u "elastic:elastic.admin" -k "https://localhost:9200"
{
  "name" : "elastk8s-cluster-es-data-nodes-0",
  "cluster_name" : "elastk8s-cluster",
  "cluster_uuid" : "MZhoTS78TaOLphwga9ACRw",
  "version" : {
    "number" : "8.4.1",
    "build_flavor" : "default",
    "build_type" : "docker",
    "build_hash" : "2bd229c8e56650b42e40992322a76e7914258f0c",
    "build_date" : "2022-08-26T12:11:43.232597118Z",
    "build_snapshot" : false,
    "lucene_version" : "9.3.0",
    "minimum_wire_compatibility_version" : "7.17.0",
    "minimum_index_compatibility_version" : "7.0.0"
  },
  "tagline" : "You Know, for Search"
}
```

> Dä¸å»ºè®®ä½¿ç”¨ -k æ ‡å¿—ç¦ç”¨è¯ä¹¦éªŒè¯ï¼Œå¹¶ä¸”åº”è¯¥ä»…ç”¨äºæµ‹è¯•ç›®çš„ã€‚æ£€æŸ¥[è®¾ç½®æ‚¨è‡ªå·±çš„è¯ä¹¦](https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-tls-certificates.html#k8s-setting-up-your-own-certificate)ã€‚

### éƒ¨ç½² Kibana å®ä¾‹

è¦éƒ¨ç½²æ‚¨çš„ Kibana å®ä¾‹ï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ã€‚

1. æŒ‡å®šä¸€ä¸ª Kibana å®ä¾‹å¹¶å°†å…¶ä¸æ‚¨çš„ Elasticsearch é›†ç¾¤å…³è”ï¼š

   ```sh
   $ cat <<EOF | kubectl apply -f -
   apiVersion: kibana.k8s.elastic.co/v1
   kind: Kibana
   metadata:
     name: elastk8s
     namespace: elastic-system
   spec:
     version: 8.4.1
     count: 1
     elasticsearchRef:
       name: elastk8s
       namespace: elastic-system
     http:
       service:
         spec:
           type: LoadBalancer # default is ClusterIP
           loadBalancerIP: 192.168.30.30
   EOF
   ```

2. ç›‘æ§ Kibana è¿è¡ŒçŠ¶å†µå’Œåˆ›å»ºè¿›åº¦ã€‚

   ä¸ Elasticsearch ç±»ä¼¼ï¼Œæ‚¨å¯ä»¥æ£€ç´¢æœ‰å…³ Kibana å®ä¾‹çš„è¯¦ç»†ä¿¡æ¯ï¼š

   ```sh
   $ kubectl get kibana -n elastic-system 
   NAME       HEALTH   NODES   VERSION   AGE
   elastk8s   green    1       8.4.1     8m9s
   ```

   ä»¥åŠç›¸å…³çš„ Podï¼š

   ```sh
   $ kubectl get pod -n elastic-system --selector='kibana.k8s.elastic.co/name=elastk8s'
   NAME                           READY   STATUS    RESTARTS   AGE
   elastk8s-kb-544557b7c6-h4vh4   1/1     Running   0          10m
   ```

3. è®¿é—® Kibanaã€‚

   ä¸º Kibana è‡ªåŠ¨åˆ›å»ºçš„ä¸€ä¸ª ClusterIP æœåŠ¡ï¼š

   ```sh
   $ kubectl get service elastk8s-kb-http -n elastic-system 
   NAME               TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)          AGE
   elastk8s-kb-http   LoadBalancer   10.96.67.213   192.168.30.30   5601:31705/TCP   11m
   ```

   > åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ https://192.168.30.30:5601

   æˆ–è€…ä½¿ç”¨ `kubectl port-forward` ä»æœ¬åœ°å·¥ä½œç«™è®¿é—® Kibanaï¼š

   ```sh
   $ kubectl port-forward service/elastk8s-kb-http 5601 -n elastic-system
   ```

   åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ https://localhost:5601ã€‚æ‚¨çš„æµè§ˆå™¨å°†æ˜¾ç¤ºè­¦å‘Šï¼Œå› ä¸ºé»˜è®¤é…ç½®çš„è‡ªç­¾åè¯ä¹¦æœªç»å·²çŸ¥è¯ä¹¦é¢å‘æœºæ„éªŒè¯ä¸”ä¸å—æ‚¨çš„æµè§ˆå™¨ä¿¡ä»»ã€‚å‡ºäºæœ¬å¿«é€Ÿå…¥é—¨çš„ç›®çš„ï¼Œæ‚¨å¯ä»¥æš‚æ—¶ç¡®è®¤è­¦å‘Šï¼Œä½†å¼ºçƒˆå»ºè®®æ‚¨ä¸ºä»»ä½•ç”Ÿäº§éƒ¨ç½²é…ç½®æœ‰æ•ˆè¯ä¹¦ã€‚


## Filebeat

### Java å †æ ˆè·Ÿè¸ª

è¿™æ˜¯ä¸€ä¸ª Java å †æ ˆè·Ÿè¸ªï¼Œå®ƒæä¾›äº†ä¸€ä¸ªç¨å¾®å¤æ‚çš„ç¤ºä¾‹ï¼š

```shell
Exception in thread "main" java.lang.IllegalStateException: A book has a null property
       at com.example.myproject.Author.getBookIds(Author.java:38)
       at com.example.myproject.Bootstrap.main(Bootstrap.java:14)
Caused by: java.lang.NullPointerException
       at com.example.myproject.Book.getId(Book.java:22)
       at com.example.myproject.Author.getBookIds(Author.java:35)
       ... 1 more
```

è¦å°†è¿™äº›è¡Œåˆå¹¶ä¸º Filebeat ä¸­çš„å•ä¸ªäº‹ä»¶ï¼Œè¯·å¯¹ filestream ä½¿ç”¨ä»¥ä¸‹å¤šè¡Œé…ç½®ï¼š

```yaml
parsers:
- multiline:
    type: pattern
    pattern: '^[[:space:]]+(at|\.{3})[[:space:]]+\b|^Caused by:'
    negate: false
    match: after
```

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæ¨¡å¼åŒ¹é…ä»¥ä¸‹è¡Œï¼š

- ä»¥ç©ºæ ¼å¼€å¤´çš„è¡Œï¼Œåè·Ÿå•è¯ `at` æˆ–è€… `...`
- ä»¥å•è¯ `Caused by: `å¼€å¤´çš„ä¸€è¡Œ

### ç»­è¡Œ

é…ç½®å°†ä»»ä½•ä»¥ `\` å­—ç¬¦ç»“å°¾çš„è¡Œä¸åé¢çš„è¡Œåˆå¹¶ï¼š

```yaml
parsers:
- multiline:
    type: pattern
    pattern: '\\$'
    negate: false
    match: before
```

### TimestampsğŸ’›

æ¥è‡ª Elasticsearch ç­‰æœåŠ¡çš„æ´»åŠ¨æ—¥å¿—é€šå¸¸ä»¥æ—¶é—´æˆ³å¼€å¤´ï¼Œç„¶åæ˜¯æœ‰å…³ç‰¹å®šæ´»åŠ¨çš„ä¿¡æ¯ï¼Œå¦‚ä¸‹ä¾‹æ‰€ç¤ºï¼š

```shell
[2015-08-24 11:49:14,389][INFO ][env                      ] [Letha] using [1] data paths, mounts [[/
(/dev/disk1)]], net usable_space [34.5gb], net total_space [118.9gb], types [hfs]
```

è¦å°†è¿™äº›è¡Œåˆå¹¶ä¸º Filebeat ä¸­çš„å•ä¸ªäº‹ä»¶ï¼Œè¯·å¯¹ filestream ä½¿ç”¨ä»¥ä¸‹å¤šè¡Œé…ç½®ï¼š

```yaml
parsers:
- multiline:
    type: pattern
    pattern: '^\[[0-9]{4}-[0-9]{2}-[0-9]{2}'
    negate: true
    match: after
```

è¯¥é…ç½®ä½¿ç”¨äº† `negate:true` å’Œ `match:after` è®¾ç½®æ¥æŒ‡å®šä»»ä½•ä¸æŒ‡å®šæ¨¡å¼ä¸åŒ¹é…çš„è¡Œéƒ½å±äºä¸Šä¸€è¡Œã€‚

###  Application events

æœ‰æ—¶æ‚¨çš„åº”ç”¨ç¨‹åºæ—¥å¿—åŒ…å«ä»¥è‡ªå®šä¹‰æ ‡è®°å¼€å§‹å’Œç»“æŸçš„äº‹ä»¶ï¼Œä¾‹å¦‚ä»¥ä¸‹ç¤ºä¾‹ï¼š

```shell
[2015-08-24 11:49:14,389] Start new event
[2015-08-24 11:49:14,395] Content of processing something
[2015-08-24 11:49:14,399] End event
```

è¦å°†å…¶åˆå¹¶ä¸º Filebeat ä¸­çš„å•ä¸ªäº‹ä»¶ï¼Œè¯·å°†ä»¥ä¸‹å¤šè¡Œé…ç½®ä¸ filestream ä¸€èµ·ä½¿ç”¨ï¼š

```yaml
parsers:
- multiline:
    type: pattern
    pattern: 'Start new event'
    negate: true
    match: after
    flush_pattern: 'End event'
```

`flush_pattern` é€‰é¡¹æŒ‡å®šå°†åˆ·æ–°å½“å‰å¤šè¡Œçš„æ­£åˆ™è¡¨è¾¾å¼ã€‚å¦‚æœæ‚¨æƒ³åˆ°æŒ‡å®šäº‹ä»¶å¼€å§‹çš„æ¨¡å¼é€‰é¡¹ï¼Œ`flush_pattern` é€‰é¡¹å°†æŒ‡å®šäº‹ä»¶çš„ç»“æŸæˆ–æœ€åä¸€è¡Œã€‚

> å¦‚æœå¼€å§‹/ç»“æŸæ—¥å¿—å—ä¸éå¤šè¡Œæ—¥å¿—æ··åˆï¼Œæˆ–è€…ä¸åŒçš„å¼€å§‹/ç»“æŸæ—¥å¿—å—ç›¸äº’é‡å ï¼Œåˆ™æ­¤ç¤ºä¾‹å°†æ— æ³•æ­£å¸¸å·¥ä½œã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹ç¤ºä¾‹ä¸­çš„å…¶ä»–ä¸€äº›æ—¥å¿—æ—¥å¿—è¡Œå°†è¢«åˆå¹¶åˆ°å•ä¸ªå¤šè¡Œæ–‡æ¡£ä¸­ï¼Œå› ä¸ºå®ƒä»¬æ—¢ä¸åŒ¹é… multiline.pattern ä¹Ÿä¸åŒ¹é… multiline.flush_patternï¼Œå¹¶ä¸” multiline.negate è®¾ç½®ä¸º trueã€‚
>
> ```shell
> [2015-08-24 11:49:14,389] Start new event
> [2015-08-24 11:49:14,395] Content of processing something
> [2015-08-24 11:49:14,399] End event
> [2015-08-24 11:50:14,389] Some other log
> [2015-08-24 11:50:14,395] Some other log
> [2015-08-24 11:50:14,399] Some other log
> [2015-08-24 11:51:14,389] Start new event
> [2015-08-24 11:51:14,395] Content of processing something
> [2015-08-24 11:51:14,399] End event
> ```

è¦å°†ä¸åŒçš„é…ç½®è®¾ç½®åº”ç”¨äºä¸åŒçš„æ–‡ä»¶ï¼Œéœ€è¦å®šä¹‰å¤šä¸ªè¾“å…¥éƒ¨åˆ†ï¼š

```yaml
filebeat.inputs:
- type: filestream 
  id: my-filestream-id
  paths:
    - /var/log/system.log
    - /var/log/wifi.log
- type: filestream 
  id: apache-filestream-id
  paths:
    - "/var/log/apache2/*"
  fields:
    apache: true
```

ä»¥ä¸‹ç¤ºä¾‹å°† Filebeat é…ç½®ä¸ºå¿½ç•¥æ‰€æœ‰å…·æœ‰ gz æ‰©å±•åçš„æ–‡ä»¶ï¼š

```yaml
filebeat.inputs:
- type: filestream
  ...
  prospector.scanner.exclude_files: ['\.gz$']
```

> é»˜è®¤æƒ…å†µä¸‹ä¸æ’é™¤ä»»ä½•æ–‡ä»¶ã€‚

ä»¥ä¸‹ç¤ºä¾‹å°† Filebeat é…ç½®ä¸ºæ’é™¤ä¸åœ¨ /var/log ä¸‹çš„æ–‡ä»¶ï¼š

```yaml
filebeat.inputs:
- type: filestream
  ...
  prospector.scanner.include_files: ['^/var/log/.*']
```

> å¦‚æœæ˜¯ç»å¯¹è·¯å¾„ï¼Œæ¨¡å¼åº”è¯¥ä»¥ `^` å¼€å¤´ã€‚

## å¸è½½ ECK

ç§»é™¤æ‰€æœ‰å‘½åç©ºé—´ä¸­çš„æ‰€æœ‰ Elastic èµ„æºï¼š

```shell
$ kubectl get namespaces --no-headers -o custom-columns=:metadata.name \
  | xargs -n1 kubectl delete elastic --all -n
```

è¿™ä¼šåˆ é™¤æ‰€æœ‰åº•å±‚ Elastic Stack èµ„æºï¼ŒåŒ…æ‹¬å®ƒä»¬çš„ Podã€Secretsã€Services ç­‰ã€‚

å¸è½½ operatorï¼š

```shell
$ kubectl delete -f https://download.elastic.co/downloads/eck/2.4.0/operator.yaml
$ kubectl delete -f https://download.elastic.co/downloads/eck/2.4.0/crds.yaml
```
